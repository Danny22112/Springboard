{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL COMPLEXITY AND OVER/UNDERFITTING\n",
    "train_accuracies = {}\n",
    "test_accuracies = {}\n",
    "neighbors = np.arange(1, 26)\n",
    "for neighbor in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_accuracies[neighbor] = knn.score(X_train, y_train)\n",
    "    test_accuracies[neighbor] = knn.score(X_test, y_test)\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"KNN: Varying Number of Neightbors\")\n",
    "plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n",
    "plt.plot(neighbors, test_accuracies.values(), label=\"Testing Accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dca255",
   "metadata": {},
   "source": [
    "finding nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6918c0d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numerical_churn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m has_nan \u001b[38;5;241m=\u001b[39m numerical_churn\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAny NaNs in the DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m, has_nan)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numerical_churn' is not defined"
     ]
    }
   ],
   "source": [
    "has_nan = numerical_churn.isna().any().any()\n",
    "print(\"Any NaNs in the DataFrame:\", has_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_churn = numerical_churn.dropna()\n",
    "\n",
    "has_nan = numerical_churn.isna().any().any()\n",
    "print(\"Any NaNs in the DataFrame:\", has_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ffb57",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044da7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eaa08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_churn.drop(\"Churn\", axis=1).values\n",
    "y = numerical_churn[\"Churn\"].values\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "# Fit your model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(y_pred_probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c878d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c29ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "???????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dceb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "sc = StandardScaler()\n",
    "logistic = LogisticRegression()\n",
    "pipe = Pipeline(steps=[('sc', sc),\n",
    "                       ('logistic', logistic)])\n",
    "\n",
    "\n",
    "C = [0.01, 0.1, 1, 10, 100]\n",
    "# Create a list of options for the regularization penalty\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create a dictionary of all the parameter options. We can access the parameters of steps of a pipeline by using '__'\n",
    "\n",
    "parameters = dict(logistic__C=C, logistic__penalty=penalty)\n",
    "\n",
    "# Conduct Parameter Optmization With Pipeline\n",
    "# Create a grid search object\n",
    "cv = GridSearchCV(pipe, parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ef8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = numerical_churn.drop(\"Churn\", axis=1).values\n",
    "y = numerical_churn[\"Churn\"].values\n",
    "\n",
    "# Check for missing values\n",
    "if pd.isnull(X).any():\n",
    "    imputer = SimpleImputer(strategy='mean')  # You can change the strategy as needed\n",
    "    X = imputer.fit_transform(X)\n",
    "    \n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X_train, y_train)\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306fc77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc930eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390fe681",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOR  STORY TELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove education and fnlwgt\n",
    "adult.drop(columns = ['education','fnlwgt','hours-per-week'], inplace = True)\n",
    "\n",
    "print('* For education level, we have 2 features that convey the same meaning, \\'education\\' \\\n",
    "        and \\'educational-num\\'. To avoid the effect of this attribute on the models to be \\\n",
    "        overstated, I am not going to use the categorical education attribute.')\n",
    "print('* I use the categorical Hours work column and drop the \\'hour-per-week\\' column')\n",
    "print('* Also, I chose not to use the \\'Fnlwgt\\' attribute that is used by the census, \\\n",
    "        as the inverse of sampling fraction adjusted for non-response and over or under sampling \\\n",
    "        of particular groups. This attribute does not convey individual related meaning.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('## Box plot')\n",
    "adult.select_dtypes(exclude = 'category').plot(kind = 'box', figsize = (10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7703d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adult.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']  # Replace with your categorical column names\n",
    "adult[categorical_columns] = adult[categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "# Separate features and target label\n",
    "adult_data = adult.drop(columns=['income'])\n",
    "adult_label = adult.income\n",
    "\n",
    "# Check for categorical columns before one-hot encoding\n",
    "categorical_cols = adult_data.select_dtypes(include='category')\n",
    "\n",
    "if categorical_cols.empty:\n",
    "    print(\"No categorical columns to encode.\")\n",
    "    adult_data_1hot = adult_data  # Keep only non-categorical data\n",
    "else:\n",
    "    # One-hot encode categorical variables\n",
    "    adult_cat_1hot = pd.get_dummies(categorical_cols, drop_first=True)\n",
    "    \n",
    "    # Select non-categorical variables\n",
    "    adult_non_cat = adult_data.select_dtypes(exclude='category')\n",
    "    \n",
    "    # Combine the non-categorical and one-hot encoded data\n",
    "    adult_data_1hot = pd.concat([adult_non_cat, adult_cat_1hot], axis=1)\n",
    "print(adult_data_1hot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Test split\n",
    "train_data, test_data, train_label, test_label = train_test_split(adult_data_1hot, adult_label, test_size  = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3cd1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "\n",
    "# Fitting only on training data\n",
    "scaler.fit(train_data)  \n",
    "train_data = scaler.transform(train_data)  \n",
    "\n",
    "# Applying same transformation to test data\n",
    "test_data = scaler.transform(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(actual, pred):\n",
    "    \n",
    "    confusion = pd.crosstab(actual, pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    TP = confusion.loc['>50K','>50K']\n",
    "    TN = confusion.loc['<=50K','<=50K']\n",
    "    FP = confusion.loc['<=50K','>50K']\n",
    "    FN = confusion.loc['>50K','<=50K']\n",
    "\n",
    "    accuracy = ((TP+TN))/(TP+FN+FP+TN)\n",
    "    precision = (TP)/(TP+FP)\n",
    "    recall = (TP)/(TP+FN)\n",
    "    f_measure = (2*recall*precision)/(recall+precision)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    error_rate = 1 - accuracy\n",
    "    \n",
    "    out = {}\n",
    "    out['accuracy'] =  accuracy\n",
    "    out['precision'] = precision\n",
    "    out['recall'] = recall\n",
    "    out['f_measure'] = f_measure\n",
    "    out['sensitivity'] = sensitivity\n",
    "    out['specificity'] = specificity\n",
    "    out['error_rate'] = error_rate\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbf kernal\n",
    "svm_clf_rbf = svm.SVC(kernel = 'rbf', C = 1, tol = 1e-3)\n",
    "svm_clf_rbf.fit(train_data, train_label)\n",
    "svm_clf_rbf_pred = svm_clf_rbf.predict(test_data)\n",
    "SVM_rbf = model_eval(test_label, svm_clf_rbf_pred)\n",
    "print('SVM using rbf kernel : %.2f percent.' % (round(SVM_rbf['accuracy']*100,2)))\n",
    "\n",
    "# Linear kernel\n",
    "svm_clf_linear = svm.SVC(kernel = 'linear')\n",
    "svm_clf_linear.fit(train_data, train_label)\n",
    "svm_clf_linear_pred = svm_clf_linear.predict(test_data)\n",
    "SVM_linear = model_eval(test_label, svm_clf_linear_pred)\n",
    "print('SVM using linear kernel : %.2f percent.' % (round(SVM_linear['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "# Poly kernal\n",
    "svm_clf_poly = svm.SVC(kernel = 'poly')\n",
    "svm_clf_poly.fit(train_data, train_label)\n",
    "svm_clf_poly_pred = svm_clf_poly.predict(test_data)\n",
    "SVM_poly = model_eval(test_label, svm_clf_poly_pred)\n",
    "print('SVM using poly kernel : %.2f percent.' % (round(SVM_poly['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "svm_clf_sigmoid = svm.SVC(kernel = 'sigmoid')\n",
    "svm_clf_sigmoid.fit(train_data, train_label)\n",
    "svm_clf_sigmoid_pred = svm_clf_sigmoid.predict(test_data)\n",
    "SVM_sigmoid = model_eval(test_label, svm_clf_sigmoid_pred)\n",
    "print('SVM using sigmoid kernel : %.2f percent.' % (round(SVM_sigmoid['accuracy']*100,2)))\n",
    "\n",
    "\n",
    "\n",
    "#printmd('### 3.3.2. Model Evaulation ')\n",
    "ovl_svm = round(pd.DataFrame([SVM_rbf, SVM_linear, SVM_poly, SVM_sigmoid], index = ['SVM_rbf','SVM_linear', 'SVM_poly', 'SVM_sigmoid']),4)\n",
    "display(ovl_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5abfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b303170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe873696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2867e823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
